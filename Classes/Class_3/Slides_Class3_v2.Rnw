% Font options: 10pm, 11pt, 12pt
% Align headings left instead of center: nocenter
\documentclass[xcolor=x11names,compress]{beamer}
%\documentclass[xcolor=x11names,compress,handout]{beamer}
\usepackage[]{graphicx}
\usepackage[]{color}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{tikz}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{dcolumn}
\usepackage{bigstrut}
\usepackage{amsmath} 
\usepackage{xcolor,colortbl}
\usepackage{amssymb}
%\newcommand{\done}{\cellcolor{teal}#1}

%% Beamer Layout %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\useoutertheme[subsection=false,shadow]{miniframes}
\useinnertheme{default}
\usefonttheme{serif}
\usepackage{Arev}
\usepackage{pdfpages}

\setbeamerfont{title like}{shape=\scshape}
\setbeamerfont{frametitle}{shape=\scshape, size=\normalsize}

\definecolor{dkblue}{RGB}{0,0,102}

\setbeamercolor*{lower separation line head}{bg=dkblue} 
\setbeamercolor*{normal text}{fg=black,bg=white} 
\setbeamercolor*{alerted text}{fg=red} 
\setbeamercolor*{example text}{fg=black} 
\setbeamercolor*{structure}{fg=black} 
 
\setbeamercolor*{palette tertiary}{fg=black,bg=black!10} 
\setbeamercolor*{palette quaternary}{fg=black,bg=black!10} 

\renewcommand{\(}{\begin{columns}}
\renewcommand{\)}{\end{columns}}
\newcommand{\<}[1]{\begin{column}{#1}}
\renewcommand{\>}{\end{column}}

\setbeamertemplate{navigation symbols}{} 
\setbeamertemplate{footline}[frame number]
\setbeamertemplate{caption}{\raggedright\insertcaption\par}

\setbeamersize{text margin left=5pt,text margin right=5pt}

\AtBeginSection{\frame{\sectionpage}}
\usepackage{xcolor}
\hypersetup{
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}

\setbeamercolor{block title}{use=structure,fg=white,bg=structure.fg!75!orange}
\setbeamercolor{block body}{parent=normal text,use=block title,bg=block title.bg!10!bg}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

<<setup, echo=F, warning=F, message=F>>=
library(knitr)
library(tidyverse)
library(stargazer)
library(xtable)
library(zeligverse)
library(broom)
library(purrr)
library(DiagrammeR)
knitr::opts_chunk$set(echo = F, warning=F, message=F, dev='png', dpi=144, cache=T)
@

<<egdata1,echo=FALSE,warning=FALSE,message=FALSE>>=
set.seed(05410)
N <- 10000
treatment <- rbinom(N,1,0.5)
outcome <- 0.3*treatment+rnorm(N,0,5)

d <- data.frame(as.factor(treatment),outcome)
@

\title{FLS 6441 - Methods III: Explanation and Causation}
\subtitle{Week 3 - Field Experiments}
\author{Jonathan Phillips}
\date{April 2019}

\begin{document}

\frame{\titlepage}

\begin{frame}
\frametitle{Rest of the Course}
\begin{itemize}
\item The rest of the course is mostly about:
\begin{itemize}
\item \textbf{Design-Based Solutions} to the Fundamental Problem of Causal Inference: Which treatment assignment mechanisms \textbf{avoid biases} and provide plausible counterfactuals
\pause
\item How much can we learn with better research design?
\pause
\item \textbf{Model-Based Solutions:} Not so much.
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Rest of the Course}
\footnotesize
\begin{table}[htbp]
  \centering
  \scalebox{0.7}{
    \begin{tabular}{|p{2.2cm}|p{5cm}|c|c|}
    \hline
          &       & \multicolumn{1}{p{2.4cm}|}{\textbf{Independence of Treatment Assignment}} & \multicolumn{1}{p{3cm}|}{\textbf{Researcher Controls Treatment Assignment?}} \bigstrut\\
    \hline
    \multicolumn{1}{|p{2.9cm}|}{\multirow{2}[4]{2cm}{\textbf{Controlled Experiments}}} & Field Experiments & \checkmark      & \checkmark  \bigstrut\\
\cline{2-4}          & Survey and Lab Experiments &  \checkmark     & \checkmark \bigstrut\\
    \hline
          &       &       &  \bigstrut\\
    \hline
    \multicolumn{1}{|p{2.9cm}|}{\multirow{3}[6]{2cm}{\textbf{Natural Experiments}}} & Randomized Natural Experiments &  \checkmark     &  \bigstrut\\
\cline{2-4}          & Instrumental Variables & \checkmark      &  \bigstrut\\
\cline{2-4}          & Discontinuities & \checkmark      &  \bigstrut\\
    \hline
          &       &       &  \bigstrut\\
    \hline
    \multicolumn{1}{|p{2.9cm}|}{\multirow{4}[8]{2cm}{\textbf{Observational Studies}}} & Difference-in-Differences &       &  \bigstrut\\
\cline{2-4}          & Controlling for Confounding &       &  \bigstrut\\
\cline{2-4}          & Matching &       &  \bigstrut\\
\cline{2-4}          & Comparative Cases and Process Tracing &       &  \bigstrut\\
    \hline
    \end{tabular}}%
  \label{tab:addlabel}%
\end{table}%
\normalsize
\end{frame}

\section{Independence}

\begin{frame}
\frametitle{Independent Treatment Assignment}
\begin{itemize}
\item Last week, we identified why it's hard to estimate causal effects:
\pause
\item \textbf{The Treatment Assignment Mechanism depends on Potential Outcomes}
\pause
\item So estimates of the ATE are \textbf{biased}
\pause
\item The solution?
\pause
\item \textbf{Treatment Assignment Mechanisms that \textit{ARE} independent of potential outcomes}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Independent Treatment Assignment}
\begin{itemize}
\item Why does Independence of Treatment Assignment help us achieve causal inference?
\begin{itemize}
\item We want to estimate:
\end{itemize}
\begin{eqnarray}
E(Y_1) - E(Y_0)
\end{eqnarray}
\pause
\begin{itemize}
\item Our data provides:
\end{itemize}
\begin{eqnarray}
E(Y_1|D=1)\text{ ,   }E(Y_0|D=0)
\end{eqnarray}
\pause
\begin{itemize}
\item With independence, $Y_1, Y_0 \perp D$:
\end{itemize}
\begin{eqnarray}
E(Y_1|D=1) = E(Y_1) \text{ ,   }  \pause E(Y_0|D=0) = E(Y_0) \\
\pause
E(Y_1|D=1) - E(Y_0|D=0) = E(Y_1) - E(Y_0) \\
\end{eqnarray}
\item Potential outcomes in the treatment and control groups are now \textbf{unbiased} and representative of \textit{all} the units
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Independent Treatment Assignment}
\begin{itemize}
\item What is the treatment assignment mechanism under \textbf{randomization}?
\pause
\begin{itemize}
\item It has nothing to do with potential outcomes!
\pause
\begin{itemize}
\item Every unit has \textbf{exactly the same} probability of treatment
\pause
\item No omitted variable bias is possible
\item No self-selection is possible
\item No reverse causation is possible
\end{itemize}
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Independent Treatment Assignment}
\begin{itemize}
\item This is the \textbf{entire} causal diagram:
\end{itemize}
\pause
<<explanation1,echo=FALSE,warning=FALSE,message=FALSE,fig.keep='high',fig.height=2.5, fig.width=4>>=
nodes <- tibble(id=1:3,
                label=c("Randomized Treatment","Outcome","Error"),
                      color="aqua")

edges <- tibble(from=c(1,3),
                to=c(2,2))

create_graph(nodes,edges, attr_theme = NULL) %>% add_global_graph_attrs('rankdir', 'LR', 'graph') %>% 
  set_edge_attrs(edge_attr=color, values="black") %>% 
  render_graph()
@
\end{frame}

\begin{frame}
\frametitle{Independent Treatment Assignment}
\begin{itemize}
\item Why does randomization remove selection bias?
\item Assume: $Y_{1i} = Y_{0i} + \alpha$, where $\alpha$ is the real constant treatment effect
\end{itemize}
$$ \hat{ATE} = E(Y_1|D=1) - E(Y_0|D=0)$$ \\ \pause
$$ \hat{ATE} = \underbrace{\alpha}_\text{Real ATE} + \underbrace{E(Y_0|D=1) - E(Y_0|D=0)}_\text{Bias}$$ \\
\begin{itemize}
\item Now, use the Independence of Treatment Assignment:
\end{itemize}
$$ E(Y_0|D=1) = E(Y_0|D=0)$$ \\
$$ \hat{ATE} = \underbrace{\alpha}_\text{Real ATE} $$ \\
\end{frame}

\begin{frame}
\frametitle{Independent Treatment Assignment}
\begin{itemize}
\item But this logic works only based on \textbf{expectations} (averages)
\pause
\begin{itemize}
\item \textit{On average}, potential outcomes will be balanced
\pause
\item That's more likely in larger samples
\pause
\item Less likely in small samples; by chance, potential outcomes may be biased
\pause
\item We have no way of \textit{verifying} if potential outcomes are biased
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Balance in Repeateed Experiments}
\begin{itemize}
\item 
\end{itemize}
\end{frame}

\section{Analysis}

\begin{frame}
\frametitle{Analyzing Field Experiments}
\begin{itemize}
\item If treatment is random we know that:
$$E(Y_1|D=1) - E(Y_0|D=0) = E(Y_1) - E(Y_0) $$
\pause
\item What is $E(Y_1|D=1)$? 
\pause 
\item What is $E(Y_0|D=0)$?
\pause
\item This is easy! 
\pause
\item Just the difference in outcome means between treatment and control units
\pause
\begin{itemize}
\item And a simple T-test for statistical significance
\pause
\item NO modelling assumptions (``non-parametric'')
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Analyzing Field Experiments}
\begin{itemize}
\item Simple Regression $=$ Difference-in-means T-test
\pause
$$Y_i \sim \alpha + \beta D_i = \epsilon_i$$
\pause
$$Y_i = Y_{0i} + (Y_{1i} - Y_{0i}) D_i + \epsilon_i$$
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Analyzing Field Experiments}
\begin{itemize}
\item Simple Regression $=$ Difference-in-means T-test
\pause
\footnotesize
\item T-test Results:
<<t-test, results='asis'>>=
d %>% mutate(treatment=factor(treatment,ordered = T,levels=c(1,0))) %>% 
  t.test(outcome~treatment, data=.) %>% 
  tidy() %>% 
  select(estimate,statistic,p.value) %>% 
  xtable(digits=5)
@
\pause
\item Regression Results ($Y_i = \alpha + \beta D_i = \epsilon_i$):
<<reg1, results='asis'>>=
d %>% lm(outcome~treatment, data=.) %>% tidy() %>% xtable(digits=5)
@
\end{itemize}
\normalsize
\end{frame}

\section{Assumptions}

\begin{frame}
\frametitle{Assumptions}
\begin{enumerate}
\item Compliance with Randomization procedure
\item Randomization produced balance on potential outcomes
\item SUTVA
\item Excludability
\end{enumerate}
\end{frame}

\begin{frame}
\frametitle{1. Compliance with Randomization procedure}
\begin{itemize}
\item Randomization is unpopular
\pause
\item Need to verify treatment allocation
\begin{itemize}
\item Transparency, documentation
\end{itemize}
\pause
\item And treatment compliance
\begin{itemize}
\item Did anyone assigned to control manage to get treatment?
\pause
\end{itemize}
\item \textbf{Design:} Double-blind assignment
\item \textbf{Checks:} Qualitative fieldwork
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{2. Randomization Produced Balanced Potential Outcomes}
\begin{itemize}
\item Impossible to Test!
\pause
\item But we can test observable pre-treatment covariates
\pause
\item If covariates are the same in the treatment and control groups, this variable \textit{cannot} explain any differences in outcomes
\pause
\item \textbf{Check:} Normally a difference in means T-test
\pause
\item \textbf{Check:} Or a Kolmogorov-Smirnov Test of identical distributions
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{2. Randomization Produced Balanced Potential Outcomes}
\begin{itemize}
\item What if a balance test comes back with a p-value < 0.05?
\pause
\item It probably will!
\begin{enumerate}
\item We are testing many variables, so some differences arise by chance
\pause
\item We have a large N, so we can detect very small differences
\pause
\end{enumerate}
\item \textbf{Check:} For balance, \textbf{What matters are \textit{substantive} differences, not p-values}
\pause
\item Two safety nets:
\begin{enumerate}
\item \textbf{Analysis:} We can still include covariates in our analysis, controlling for 'residual' imbalance
\pause
\item \textbf{Analysis:} We are using p-values in our \textit{analysis}, which take into account 'chance' imbalance
\pause
\end{enumerate}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{3. SUTVA}
\begin{itemize}
\item Stable Unit Treatment Value Assumption = \textbf{No Interference}
\pause
\item Technically, treatment of unit $j$ does not affect the potential outcomes for unit $i$
\pause
$$(Y_{1i}, Y_{0i}) \perp D_j$$
\pause
$$Y_i(D_i, D_j, D_k, D_l, D_m, D_n, D_o, D_p...) = Y_i(D_i)$$
\pause
\item But spillovers are common! If you get an award, I might feel more motivated or less motivated
\pause
\begin{itemize}
\item \textbf{Design:} Limit risk of spillovers, eg. leave 20 miles between each unit
\item \textbf{Check:} Qualitative fieldwork
\item \textbf{Analysis:} Try to \textit{measure} spillovers
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{4. Excludability}
\begin{itemize}
\item \textbf{Nothing else correlated with treatment affects potential outcomes}
\pause
\item Assignment to treatment causes a \textbf{'second'} treatment
\pause
\item Eg. We share information about specific politicians on the radio, but the politicians then counter with their own broadcasts
\pause
\item Our treatment effect is no longer \textit{only} the effect of our information
\pause
\item Or do we want to measure these additional effects?
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{4. Excludability}
\begin{itemize}
\item \textbf{Nothing else correlated with treatment affects potential outcomes}
\pause
\item Some responses to treatment we want to capture
\begin{itemize}
\item Eg. One reason richer families change their attitudes to government is because they start paying taxes
\end{itemize}
\pause
\item Others we don't want to capture
\begin{itemize}
\item Eg. Measurement bias: Researchers treat treated units differently and record higher outcomes for them
\end{itemize}
\item \textit{Design:} Careful specification of treatment and control
\end{itemize}
\end{frame}

\section{Implementing Field Experiments}

\begin{frame}
\frametitle{Implementing Field Experiments}
\begin{itemize}
\item How do we randomize?
\begin{itemize}
\item Hard! We can't just 'pick' treated units off the top of our heads
\pause
\item Computers are deterministic
\pause
\item The best we can do is to use atmospheric noise or radioactive decay
\pause
\end{itemize}
\item In the real world, randomization is hard
\begin{itemize}
\item Pressure to help the most needy
\pause
\item Political pressure
\pause
\item We don't want to be guinea pigs!
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Implementing Field Experiments}
\begin{itemize}
\item How do we randomize?
\pause
\item So how do we confirm that randomization has succeeded?
\pause
\begin{itemize}
\item We can't directly test potential outcomes
\end{itemize}
\begin{enumerate}
\item \textbf{Qualitative research:} to reconstruct the treatment process
\pause
\item \textbf{Balance tests:} We can directly test other variables between treatment and control
\begin{itemize}
\item Randomization balances \textit{all} variables, not just potential outcomes
\end{itemize}
\end{enumerate}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Implementing Field Experiments}
\begin{itemize}
\item How do we randomize?
\pause
\item Three options to assign treatment and control 'independent' of potential outcomes:
\pause
\begin{itemize}
\item We have N units and want equal probability of treatment for each:
\end{itemize}
\begin{enumerate}
\item Flip a coin for every unit so every unit has probability $0.5$ of treatment
\pause
\item Randomize the order of the units and assign the first $\frac{N}{2}$ units to treatment
\pause
\item Pair units and flip a coin to assign one to treatment so exactly $\frac{N}{2}$ get treatment
\end{enumerate}
\item What's the difference between these three options?
\end{itemize}
\end{frame}

\section{Designing Field Experiments}

\end{document}

%Random sample vs. Random treatment
%why 50:50
% Random balance works for measurable...and also for UNobservables, including POs. Random assignment really random sampling of Y0s and Y1s
% Balance tests for full distribution, not just mean
% Balance tests - not about p-values as large sample sizes, but absolute substantive similarity
% Balance tests really unnecessary as p-values already take chance of bad randomisation into account (https://janhove.github.io/reporting/2014/09/26/balance-tests)
% Blocking as pre-control
% 95% interval repeated experiments example
% *Deworming wars - As example of difficulty of interpreting and aggregating field experiments
% Scope of sample crucial, eg. uninsured in HIE experiment in Angrist and Pischke
% Experiments don't just show obvious - need to test where theories point in different directions, so are falsifiable
% Example of failing to nail down mechanism - thought was acidic diet, not vitamin C that lemons/oranges cured scurvy in A&P 
% Experimental effects as random variables with distribution in repeated experiments
% Attrition
% SUTVA
% Ask what can go wrong with field exp?
% Problem of unrealistic treatments not reflecting naturalistic - *USE Ng example
% Hawthorne effects for next week
% GG: Realism of treatments, participants, context and outcome measures
% Testing general theoretical mechanisms vs. specific policy
% Testing crossovers to reveal interactions/most effective
% Outcomes defined over time; large effects decay
% Downstream experiments
% Heterogeneous treatment effects
% Randomization as forcing to be compoletely missing at random
% Non-compliance, double-blind, measurement bias etc.
% Ass: Excludability from PROCESS of treatment and from parallel correlated treatments (*net effects, placebo effects of pill), 
% SUTVA as Y_i(d_i, d_j, d_K...). Leaving gaps between treated and control villages etc. But sometimes want to include and measure these spillovers. Pose as Q - why SUTVA a problem?

% Give examples of bad designs and get them to identify why
% Does sample reflect population? If not, conclusions restricted to characteristics of sample.
% Effects include net all downstream effects (avoid post-treatment bias). Eg. in equi, more cash leads to changes in education choices, which leads to more cash etc. If full offset by households of government intervention, see no treatment effect but something important still changed. 
% In general, want to randomize at lowest level, and sample in smaller clusters. But spillovers matter, eg. deworming v.dif at school level
% Clustered SEs, multi-testing (Bonferonni vs. Index of outcomes)
%Data-mining on heterog effects - need to justify by theory. Eg. treated five villages and worked in one - do we believe it?
% Covariates to reduce variance, increase precision
% GE effects, eg. changes in sorting, competition, expectations, norms
%Hawthorne effects (for next week)
% Generalizability based on treatment intensity and sample characteristics (often convenience samples used for experiments, ironically non-random samples). Theory valuable for generalization.

%\pause
%\item But we can assess balance in \textit{observable} covariates
%\item What if some covariates are imbalanced? %Expected 1/20. Still need to correct as could be real bias.


%setwd('C:\\Users\\Jonny\\Google Drive\\Academic\\USP\\Class\\Week 1 - Intro\\Lecture Slides')
%knitr::knit("Slides_Wk1_intro_5.Rnw")