---
title: "Exercise: Understanding Potential Outcomes"
output: pdf_document
fontsize: 16pt
---

```{r setup, echo=F,warning=F, error=F, message=F}
knitr::opts_chunk$set(echo = F, warning=F, error=F, message=F, fig.height=3, fig.width=3, include=F)
library(tidyverse)
library(stargazer)
```

Let's see how the presence of \textbf{non-compliance} with treatment affects our treatment effect estimates in some simple 'fake' data. And how \textbf{instrumental variables} can help us estimate an accurate average treatment effect even when there is non-compliance.

1. First, let's generate an 'income' variable for 10,000 people. The data should be drawn randomly from the normal distribution with mean 500 and standard deviation 50.

```{r}
set.seed(54321)
N <- 10000
d <- tibble(income=rnorm(N,500,50))
```

2. Now let's simulate potential outcomes (let's say the outcome is 'attitude to redistribution') for each person that depend on their income. Assume:

$$y_0=N(10,2)+\frac{income}{100}$$ 

$$y_1=y_0+2$$

So there is a constant treatment effect of 2.

```{r}
d <- d %>% mutate(y_0=rnorm(N,10,2) + income/100,
                  y_1=y_0+2)
```

3. The key thing to remember with non-compliance is that there is a difference between **treatment assignment** and actual **treatment**. Treatment assignment in our case will be completely random, so create a random binomial variable with 50\% chance of each person being assigned to treatment.

```{r}
d <- d %>% mutate(D_assign=rbinom(N,1,0.5))
```

4. For most people, treatment will be the same as treatment assignment, so make another 'treatment' variable that directly copies 'treatment assignment'. This is what an experiment with zero non-compliance would look like.

```{r}
d <- d %>% mutate(D=D_assign)
```

5. To introduce non-compliance, let's adjust this 'treatment' variable so that rich people with an income above 550 are **'Never-takers'** - regardless of their value for treatment assignment, they *never* receive treatment (so treatment=0).

```{r}
d <- d %>% mutate(D=ifelse(income>550,0,D))
```

6. Now calculate the observed outcome based on the potential outcomes and actual treatment status.

```{r}
d <- d %>% mutate(y_obs=case_when(D==0~y_0,
                                  D==1~y_1))
```

7. Now let's calculate the 'naive' Average Treatment Effect ignoring non-compliance by running a regression of the observed outcomes on treatment (actual treatment, not treatment assignment). What is your estimate of the average treatment effect? How does this compare to the treatment effect we specified earlier?

```{r, results='asis'}
d %>% lm(y_obs ~ D, data=.) %>% stargazer(single.row=T, header=F, title="Q7")
```

8. Now let's adjust the data so that people with an income below 450 are all **Always-Takers**, so regardless of treatment assignment they always receive treatment (treatment=1). Remember to re-calculate observed outcomes afterwards.

```{r}
d <- d %>% mutate(D=ifelse(income<450,1,D),
                  y_obs=case_when(D==0~y_0,
                                  D==1~y_1))
```

9. Re-run the regression from Q7 on our dataset that includes both never-takers and always-takers. How does this change our estimate of the Average Treatment Effect?

```{r, results='asis'}
d %>% lm(y_obs ~ D, data=.) %>% stargazer(single.row=T, header=F, title="Q9")
```

10. Given this bias in our estimate, we can try to use treatment assignment as an **instrumental variable** for actual treatment. To do this, we first need to run the **First Stage** regression to show that treatment assignment explains treatment. ($D_i \sim Z_i$) Is treatment assignment a strong instrument for treatment? What evidence do you have?

```{r, results='asis'}
d %>% lm(D ~ D_assign, data=.) %>% stargazer(single.row=T, header=F, title="Q10")
```

11. Save the fitted values from this regression in Q10 as a new column in your dataset.

```{r}
d <- d %>% mutate(First_stage_fitted=lm(D ~ D_assign, data=.)$fitted.values)
```

12. Now for the second stage of our instrumental variables analysis, use a regression to estimate how these fitted values explain the observed outcomes. ($y_i^{obs} \sim \hat{D_i}$) How does the result compare to our initial assumption about the size of the treatment effect?

```{r, results='asis'}
d %>% lm(y_obs ~ First_stage_fitted, data=.) %>% stargazer(single.row=T, header=F, title="Q12")
```

13. How should we interpret this estimate? What group does it apply to?

14. The only thing wrong with our 2-Stage Least Squares Regression above is that the standard errors are not accurate. To correct this, we can use an all-in-one Instrumental Variables estimator, eg. _ivreg_ in the _AER_ package in R or _ivregress_ in Stata. How do the standard errors change?

```{r, results='asis'}
library(AER)
d %>% ivreg(y_obs ~ D|D_assign, data=.) %>% stargazer(single.row=T, header=F, title="Q14")
```

15. Finally, let's see how our treatment effect estimate changes when we introduce some \textbf{defiers}: Change your data so that anyone with income less than 480 who was assigned to control actually receives treatment AND so that anyone assigned to treatment actually receives control. Calculate observed outcomes again. Then run the Instrumental Variables regression (2SLS or the all-in-one) and interpret the results.

```{r, results='asis'}
d <- d %>% mutate(D=case_when(income<480 & D_assign==0~1,
                      income<480 & D_assign==1~0,
                      income>=480~D),
             y_obs=case_when(D==0~y_0,
                                  D==1~y_1))

d %>% ivreg(y_obs ~ D|D_assign, data=.) %>% stargazer(single.row=T, header=F, title="Q15")
```
