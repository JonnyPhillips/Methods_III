---
title: "Exercise: Matching"
output: pdf_document
fontsize: 16pt
---

```{r setup, echo=F,warning=F, error=F, message=F}
knitr::opts_chunk$set(echo = F, warning=F, error=F, message=F, fig.height=3, fig.width=3, include=F)
library(tidyverse)
library(stargazer)
library(MatchIt)
library(optmatch)
library(rgenoud)
library(cem)
```

Let's simulate some fake data and see when we are able to recover the correct treatment effect using matching methods. 

1. First, let's generate some confounder variables for 100 people. 
(a) The variable 'age' should be drawn randomly from the normal distribution with mean 40 and standard deviation 7.
(b) The variable 'gender' should be drawn randomly from the binomial distribution with a 0.5 probability of being male or female.
(c) The variable 'income' should be drawn randomly from the normal distirbution with mean 500 and standard deviation 50.
(d) The variable 'education' should be randomly drawn from one of four numerical categories with equal probability: 0 (None), 1 (Primary), 2 (Secondary), 3 (Tertiary)

```{r}
set.seed(54321)
N <- 100
d <- tibble(age=rnorm(N,40,7),
            gender=rbinom(N,1,0.5),
            income=rnorm(N,500,50),
            education=sample(c(0,1,2,3),N,
                             prob=c(0.25,0.25,0.25,0.25), replace=T))
```

2. Our outcome is going to be attitudes to redistribution. Use the expressions below to simulate potential outcomes, with a treatment effect of 5.

$$y_0=N(10,2)+5*age - 100*gender + income - education*30$$ 

$$y_1=y_0+5$$

```{r}
set.seed(54321)
d <- d %>% mutate(y_0=rnorm(N,10,2) + 5*age - 100*gender + income - education*30,
                  y_1=y_0+5)
```

3. Treatment $D$ is receiving a government social program, but treatment is **not** randomly  assigned in any way. Instead, treatment depends on age, gender, income and education. Binary (1/0) treatment is determined by the following expression:

$$D=\begin{cases}
1 \text{ if } 2*gender + \frac{age}{2} + \frac{income}{50} + education*2>34 \\ 
0 \text{ else }
\end{cases}$$

```{r}
d <- d %>% mutate(D=case_when(2*gender+age/2+income/50+education*2>34~1,
                              T~0))

#summary(2*d$gender + d$age/2 + d$income/50 + d$education*2)
```

4. Calculate observed outcomes based on potential outcomes and treatment.

```{r}
d <- d %>% mutate(y_obs=case_when(D==0~y_0,
                                  D==1~y_1))
```

5. As always, as a benchmark, let's run the 'naive' regression of the outcome on the treatment with no controls. Why is the result different from our assumed treatment effect?

```{r}
d %>% lm(y_obs ~ D, data=.) %>% summary()
```

6. Our first task is to try and 'match' one treated unit with one control unit so that the *only* thing that is different about them is their treatment status. Take the first treated unit in your dataset. What are its values of gender, age, income and education? Manually, by trial-and-error (not using any package or pre-prepared function), identify the most similar *control* unit.

```{r}
treated_unit <- d %>% filter(D==1) %>% slice(1)
control_units <- d %>% filter(D==0 & gender==1 & education==3)
control_unit <- control_units %>% filter(age<36 & age>32 & income>450 & income<570)
```

7. Compare the outcome between your matched treated unit and control unit. Is this consistent with our assumed treatment effect? Why/why not?

```{r}
treated_unit$y_obs - control_unit$y_obs
```

8. Matching repeats this process for multiple units and then finds the average difference in outcomes between the treated and control units. Use the _matchit_ package to conduct 'nearest neighbour' (the default) matching on your dataset for the two discrete confounder variables: gender and education. What is the result of the matching procedure - how many units were matched?

```{r}
matched_data_Q8 <- matchit(D ~ gender + education + age + income, data=d)
```

9. Use _match.data_ to extract the matched dataset and calculate the average difference in means between the treated and control groups. How does the result compare to the naive regression in Q5?

```{r}
matched_data_Q8 %>% match.data() %>% 
  group_by(D) %>%
  summarize(y_obs=mean(y_obs,na.rm=T)) %>%
  arrange(-D) %>%
  mutate(diff_y_obs=y_obs-lead(y_obs))
```

10. To understand how matching changed our dataset, check the _summary_ information about your matched data. On which variables did balance improve and on what variables did it deteriorate?

```{r}
matched_data_Q8 %>% summary()
```

11. Matching *ONLY* makes a difference if we throw away some data - the data for which we cannot find good matches. The more data we throw away, the better matched/balanced is our remaining data. Conduct your nearest neighbour matching procedure again, but this time use the _exact_ parameter to require that matched treated and control units have exactly the same gender and education. How many units are matched now? Has balanced improved? What is the average difference in mean outcomes between treated and control groups?

```{r}
matched_data_Q11 <- matchit(D ~ gender + education + age + income, data=data.frame(d), exact=c("gender","education"))

matched_data_Q11 %>% summary()

matched_data_Q11 %>% match.data() %>% 
  group_by(D) %>%
  summarize(y_obs=mean(y_obs,na.rm=T)) %>%
  arrange(-D) %>%
  mutate(diff_y_obs=y_obs-lead(y_obs))
```

12. An alternative way of limiting the number of matches is to specify a maximum distance measure beyond which paired units are dropped. Run your matching procedure again, specifying a _caliper_ of 2 (or try other values if this doesn't work). How many units are matched now? Has balanced improved? What is the average difference in mean outcomes between treated and control groups?

```{r}
matched_data_Q12 <- matchit(D ~ gender + education + age + income, data=data.frame(d), caliper=2)
matched_data_Q12 %>% summary()

matched_data_Q12 %>% match.data() %>% 
  group_by(D) %>%
  summarize(y_obs=mean(y_obs,na.rm=T)) %>%
  arrange(-D) %>%
  mutate(diff_y_obs=y_obs-lead(y_obs))
```

13. One problem with this nearest neighbour matching procedure is that it is 'dumb', matching one pair and then another, even if the distance between units would be lower if the matches were switched around. Try using the 'optimal' and 'genetic' methods of _matchit_ to improve your analysis. Has balanced improved? What is the average difference in mean outcomes between treated and control groups?

```{r}
matched_data_Q13 <- matchit(D ~ gender + education + age + income, data=data.frame(d), method="optimal")
matched_data_Q13 %>% summary()

matched_data_Q13 %>% match.data() %>% 
  group_by(D) %>%
  summarize(y_obs=mean(y_obs,na.rm=T)) %>%
  arrange(-D) %>%
  mutate(diff_y_obs=y_obs-lead(y_obs))

matched_data_Q13_genetic <- matchit(D ~ gender + education + age + income, data=data.frame(d), method="genetic")
matched_data_Q13_genetic %>% summary()

matched_data_Q13_genetic %>% match.data() %>% 
  group_by(D) %>%
  summarize(y_obs=mean(y_obs,na.rm=T)) %>%
  arrange(-D) %>%
  mutate(diff_y_obs=y_obs-lead(y_obs))
```

14. Finally, try conducting matching with the Coarsened Exact Matching (CEM) methodology.

```{r}
matched_data_Q14 <- matchit(D ~ gender + education + age + income, data=data.frame(d), method="cem")
matched_data_Q14 %>% summary()

matched_data_Q14 %>% match.data() %>% 
  group_by(D) %>%
  summarize(y_obs=mean(y_obs,na.rm=T)) %>%
  arrange(-D) %>%
  mutate(diff_y_obs=y_obs-lead(y_obs))
```

15. The risk of matching is that we have so many options that we can keep trying until we find a 'big' effect. So we should always be guided by a clear, measurable goal: improving balance. Try various matching methods and options to try and maximize balance on the four confounding variables.



